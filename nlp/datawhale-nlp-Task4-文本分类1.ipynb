{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task4 基于深度学习的文本分类1\n",
    "\n",
    "在上一章节，我们使用传统机器学习算法来解决了文本分类问题，从本章开始我们将尝试使用深度学习方法。\n",
    "\n",
    "## 基于深度学习的文本分类\n",
    "\n",
    "与传统机器学习不同，深度学习既提供特征提取功能，也可以完成分类的功能。从本章开始我们将学习如何使用深度学习来完成文本表示。\n",
    "\n",
    "### 学习目标\n",
    "\n",
    "- 学习FastText的使用和基础原理\n",
    "- 学会使用验证集进行调参\n",
    "\n",
    "### 文本表示方法 Part2\n",
    "\n",
    "#### 现有文本表示方法的缺陷\n",
    "\n",
    "在上一章节，我们介绍几种文本表示方法：\n",
    "\n",
    "- One-hot\n",
    "- Bag of Words\n",
    "- N-gram\n",
    "- TF-IDF\n",
    "\n",
    "也通过sklean进行了相应的实践，相信你也有了初步的认知。但上述方法都或多或少存在一定的问题：转换得到的向量维度很高，需要较长的训练实践；没有考虑单词与单词之间的关系，只是进行了统计。\n",
    "\n",
    "与这些表示方法不同，深度学习也可以用于文本表示，还可以将其映射到一个低纬空间。其中比较典型的例子有：FastText、Word2Vec和Bert。在本章我们将介绍FastText，将在后面的内容介绍Word2Vec和Bert。\n",
    "\n",
    "#### FastText\n",
    "\n",
    "FastText是一种典型的深度学习词向量的表示方法，它非常简单通过Embedding层将单词映射到稠密空间，然后将句子中所有的单词在Embedding空间中进行平均，进而完成分类操作。\n",
    "\n",
    "所以FastText是一个三层的神经网络，输入层、隐含层和输出层。\n",
    "\n",
    "\n",
    "![fast_text](https://img-blog.csdnimg.cn/20200714204856589.png)\n",
    "\n",
    "\n",
    "FastText在文本分类任务上，是优于TF-IDF的：\n",
    "\n",
    "- FastText用单词的Embedding叠加获得的文档向量，将相似的句子分为一类\n",
    "- FastText学习到的Embedding空间维度比较低，可以快速进行训练\n",
    "\n",
    "如果想深度学习，可以参考论文：\n",
    "\n",
    "Bag of Tricks for Efficient Text Classification, https://arxiv.org/abs/1607.01759\n",
    "\n",
    "### 基于FastText的文本分类\n",
    "\n",
    "FastText可以快速的在CPU上进行训练，最好的实践方法就是官方开源的版本：\n",
    "https://github.com/facebookresearch/fastText/tree/master/python\n",
    "\n",
    "- pip安装\n",
    "\n",
    "- \n",
    "\n",
    "```\n",
    "pip install fasttext\n",
    "```\n",
    "\n",
    "- 源码安装\n",
    "\n",
    "```\n",
    "git clone https://github.com/facebookresearch/fastText.git\n",
    "cd fastText\n",
    "sudo pip install .\n",
    "```\n",
    "\n",
    "两种安装方法都可以安装，如果你是初学者可以优先考虑使用pip安装。\n",
    "\n",
    "- 分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8184892859301263\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 转换为FastText需要的格式\n",
    "train_df = pd.read_csv('train_set.csv', sep='\\t', nrows=15000)\n",
    "train_df['label_ft'] = '__label__' + train_df['label'].astype(str)\n",
    "train_df[['text','label_ft']].iloc[:-5000].to_csv('train.csv', index=None, header=None, sep='\\t')\n",
    "\n",
    "import fasttext\n",
    "model = fasttext.train_supervised('train.csv', lr=1.0, wordNgrams=2, \n",
    "                                  verbose=2, minCount=1, epoch=25, loss=\"hs\")\n",
    "\n",
    "val_pred = [model.predict(x)[0][0].split('__')[-1] for x in train_df.iloc[-5000:]['text']]\n",
    "print(f1_score(train_df['label'].values[-5000:].astype(str), val_pred, average='macro'))\n",
    "# 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何使用验证集调参\n",
    "\n",
    "在使用TF-IDF和FastText中，有一些模型的参数需要选择，这些参数会在一定程度上影响模型的精度，那么如何选择这些参数呢？\n",
    "\n",
    "- 通过阅读文档，要弄清楚这些参数的大致含义，那些参数会增加模型的复杂度\n",
    "- 通过在验证集上进行验证模型精度，找到模型在是否过拟合还是欠拟合\n",
    "\n",
    "\n",
    "\n",
    "![train_val](https://img-blog.csdnimg.cn/20200714204403844.png)\n",
    "\n",
    "这里我们使用10折交叉验证，每折使用9/10的数据进行训练，剩余1/10作为验证集检验模型的效果。这里需要注意每折的划分必须保证标签的分布与整个数据集的分布一致。\n",
    "\n",
    "```\n",
    "label2id = {}\n",
    "for i in range(total):\n",
    "    label = str(all_labels[i])\n",
    "    if label not in label2id:\n",
    "        label2id[label] = [i]\n",
    "    else:\n",
    "        label2id[label].append(i)\n",
    "```\n",
    "\n",
    "通过10折划分，我们一共得到了10份分布一致的数据，索引分别为0到9，每次通过将一份数据作为验证集，剩余数据作为训练集，获得了所有数据的10种分割。不失一般性，我们选择最后一份完成剩余的实验，即索引为9的一份做为验证集，索引为1-8的作为训练集，然后基于验证集的结果调整超参数，使得模型性能更优。\n",
    "\n",
    "### 本章小结\n",
    "\n",
    "本章介绍了FastText的原理和基础使用，并进行相应的实践。然后介绍了通过10折交叉验证划分数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.056165381136417614\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised('train.csv', lr=0.02, wordNgrams=3, \n",
    "                                  verbose=2, minCount=2, epoch=25, loss=\"softmax\")\n",
    "\n",
    "val_pred = [model.predict(x)[0][0].split('__')[-1] for x in train_df.iloc[-5000:]['text']]\n",
    "print(f1_score(train_df['label'].values[-5000:].astype(str), val_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastText库的使用\n",
    "fastText 是一个用于高效学习单词表示和句子分类的库。\n",
    "中文文档：http://fasttext.apachecn.org/#/doc/zh/support"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "空的输入或输出路径.\n",
    "\n",
    "以下参数是强制性的:\n",
    "  -input              训练文件路径\n",
    "  -output             输出文件路径\n",
    "\n",
    "以下参数是可选的:\n",
    "  -verbose            冗长等级 [2]\n",
    "\n",
    "以下字典参数是可选的:\n",
    "  -minCount           词出现的最少次数 [5]\n",
    "  -minCountLabel      标签出现的最少次数 [0]\n",
    "  -wordNgrams         单词 ngram 的最大长度 [1]\n",
    "  -bucket             桶的个数 [2000000]\n",
    "  -minn               char ngram 的最小长度 [3]\n",
    "  -maxn               char ngram 的最大长度 [6]\n",
    "  -t                  抽样阈值 [0.0001]\n",
    "  -label              标签前缀 [__label__]\n",
    "\n",
    "以下用于训练的参数是可选的:\n",
    "  -lr                 学习速率 [0.05]\n",
    "  -lrUpdateRate       更改学习速率的更新速率 100]\n",
    "  -dim                字向量的大小 [100]\n",
    "  -ws                 上下文窗口的大小 [5]\n",
    "  -epoch              迭代次数 [5]\n",
    "  -neg                负样本个数 [5]\n",
    "  -loss               损失函数 {ns, hs, softmax} [ns]\n",
    "  -thread             线程个数 [12]\n",
    "  -pretrainedVectors  监督学习的预训练词向量 []\n",
    "  -saveOutput         是否应该保存输出参数 [0]\n",
    "\n",
    "以下量化参数是可选的:\n",
    "  -cutoff             要保留的词和 ngram 的数量 [0]\n",
    "  -retrain            微调 embeddings（假如应用 -cutoff 参数的话） [0]\n",
    "  -qnorm              分别量化范数 [0]\n",
    "  -qout               量化分类器 [0]\n",
    "  -dsub               每个子向量的大小 [2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考：\n",
    "原文链接：https://blog.csdn.net/cymy001/java/article/details/90576224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
